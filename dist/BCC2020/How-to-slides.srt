1
0: 0: 0, 0 –> 0: 0: 8, 0
Hello everyone, thank you for connecting to this talk. My name is Delphine, but I am communicating with you through an artificial voice called Joanna.

2
0: 0:8,5 –> 0: 0: 17,0
  I work at the Pennsylvania State University, with the Galaxy Team. I am here today to talk about the automatic generation of training material, that has been used to generate this presentation.

3
0: 0: 17,0 –> 0: 0: 29,0
This work has initially been started with James Taylor and Jeff Leek’s Lab, and was one of the projects he could not finish. We took over the project to continue his work for open science.

4
0: 0: 29,5 –> 0: 0: 37.0
Online training is a wonderful tool to learn new skills at our own rythm. Trainers often have to consider the best way to convey their knowledge.

5
0: 0: 37,5 –> 0: 0: 47,0
Some people learn better by reading, some other by listening or doing. Ideally all material would be available in all formats, but it can be very time consuming.

6
0: 0: 47,5 –> 0: 0: 55,0
I have been participating to the Galaxy Training community. Our goal is to provide quality training material to trainers and trainees.

7
0: 0: 55,5 –> 0: 1: 02,0
Facilitating the contribution of new materials, and the maintenance of older ones, can participate to this effort to make knowledge accessible.

8
0: 1 : 02,5 –> 0: 1: 10,0
To improve the time spent on formating these trainings, we are building a workflow to generate three type of support from a single markdown document :

9
0: 1: 10,5 –> 0:1: 15,0
A hands-on page, a slide show, and a video lecture using text-to-speech…

10
0: 1: 15,5 –> 0:1: 19,0
In this lecture, we will show how to generate these different types of teaching material easily.

11
0: 1: 19,5 –> 0:1: 31,0
First, I will talk about the general processing workflow and tools that we used for this project. I will explain how to structure the original document, and how to control each output.

12
0: 1: 31,5 –> 0:1: 37,0
Finally, I will talk about how we generate the different documents, and the future evolution of this project…

13
0: 1: 37,5 –> 0:1: 46,0
The original document is written in Markdown, and we start by creating two documents from it.One is the full hands-on document, and the other is a slide show.

14
0: 1: 46,5 –> 0:1: 57,0
We perform these conversion using the pandoc tool. Pandoc is a universal document converter. It supports dozen of formats, including several flavors of markdown and proprietary formats.

15
0: 1: 57,5 –> 0:2: 05,0
One of the reason we selected this tool to generate the HTML documents, is because it allows us to create stand-alone html files.

16
0: 2: 05,5 –> 0:2: 19,0
Standalone html files are easier to treat, because it eliminates dependencies problems. It also allows the use of css, and without including it in the markdown, improving the neutrality of the original material.

17
0: 2: 19,5 –> 0:2: 26,0
In addition, the integration of pandoc to the workflow could allow us to expand the range of material we can produce in the future.

18
0: 2: 26,5 –> 0:2: 35,0
Once we generated the slide show document, we extract the text dedicated to the text-to-speech. They are identified by special tags in the markdown document.

19
0: 2: 35,5 –> 0:2: 46,0
We parse the html document with a javascript script to extract the text destined to be spoken. From this content, we create a script file, with a line corresponding to the speech of a slide.

20
0: 2: 46,5 –> 0:2: 52,0
These extracted blocks of text can often be the same one that are used to be more descriptive in the main document.

21
0: 2: 52,5 –> 0:3: 0,0
From the same HTML slide show, we extract one image per slide, using a tool that neither the artificial voice nor me are sure how to pronounce.

22
0:3: 0,50–> 0:3: 11,0
This tool has one great advantage : it is not dependent on how we built our H.T.M.L. , making it very adaptable. We now have one image, and one line per slide in the script file.

23
0:3: 11,5 –> 0:3: 24,0
From this 2 parts, we assemble the video with ari package. Ari is a R package that uses Amazon Polly services to convert text to speech, and stiches together voice and images to produce a video.

24
0:3: 24,5 –> 0:3: 35,0
It is developped in Johns Hopkins Data Science Lab. As the script file used to generate the video contains one line of text per slide, it is easy to modify it to generate subtitles.

25
0:3: 35 ,5 –> 0:3: 45,0
All the tools are encapsulated in scripts managed with yarn. You simply need to provide the path for one of the possible output, and the necessary steps are run automatically.


26
0:3: 45,5 –> 0:3: 54,0
So, everything starts with our initial material in Markdown. This document will contain four sets of content : The biggest set is the common core between all supports.

27
0:3: 54,5 –> 0:4: 2,0
There are two mutually exclusive sets corresponding to the content to be displayed only in the slide show, or only in the hands-on document.

28
0:4: 2,5 –>  0:4: 11,0
The last set contain paragraphs destined to be read by the artificial voice. This set can often overlap with the explanatory text dedicated to the hands-on document.

29
0:4: 11,5 –>  0:4: 21,0
These set are identified by Markdown tags. For those of you who are not familiar with markdown, I will present the lanquage rapidly before looking into these specific tags.

30
0:4: 21,5 –>  0:4: 34,0
Markdown is a text format used to generate html pages. There is no formatting in the raw text, as the formatting will be described in a css file and applied when the markdown is converted into html.

31
0:4: 34,5 –>  0:4: 43,0
For example, in this slide, you can see that titles are described with hashtags. The top level with one, and one more for each lower level.

32
0:4: 43,5 –>  0:4: 51,0
Lists can be encoded with number for ordered lists, or hyphens for non ordered one. The first number of an ordered list is set to the number in the support,

33
0:4: 51,5 –>  0:4: 59,0
but the following will increment by 1 independently of the number actually written in the markdown. Markdown is a format pretty simple to use,

34
0:4: 59,5 –>  0:5: 04,0
but it is important to notice that it is very sensitive to spacing and necessitate some rigor.


35
0:5: 04,5 –>  0:5: 15,0
Although used by a lot of tools, Markdown comes in many flavors when the elements of style become more complex.
Every platform has different syntaxes to apply a certain formatting to part of the document.

36
0:5: 15,5 –>  0:5: 28,0
In this version of pandoc, you can tag a container with a class name or ID between curly brackets. The containers limits are defined by square brackets in case of in-line content, and with flanking colons for special paragraphs.

37
0:5: 28,5 –>  0:5: 35,0
The start of the paragraph is marked with at least three colons, and the end by the next line of colons containing more colons than the first one.

38
0:5: 35,5 –>  0:5: 47,0
The name between brackets are the names of the style that will be applied to the content. A content class is identified by a period followed by the class name, and its ID is identified by a hashtag followed by the ID.

39
0:5: 47,5 –>  0:5: 57,0
In Pandoc, One Basic structure of the document is the header. It contains metadata about the document, and generally require a title, date, and authors.

40
0:5: 57 ,5 –>  0:6: 07,0
It is used to build a cover slide containing the metadata. For the moment, this slide is deactivated because it causes problems with the parsing looking for speech paragraphs.

41
0:6: 07,5 –>  0:6: 15,0
The video cannot be built with a discordance between the number of slides and the lines of text. As we cannot modify the title slide, we can’t generate enough lines for the voice.

42
0:6: 15,5 –>  0:6: 26,0
Contrary to other conversion tools, you do not need to insert a line to separate slides in pandoc markdown. The change of slide is done at each top level header.

43
0:6: 26,5 –>  0:6: 38,0
This permits to not have random lines appearing in the hands-on document. If you wish to continue display a title across several slides, use the slide only tag to hide the additional titles in the main HTML document.

44
0:6: 38,5 –>  0:6: 42,0
You can also use the same tag on the main slide title to silence the whole slide.


45
0:6: 42,5 –>  0:6: 53,0
The three tags used to mark the different sets of content are : document, slide only, and spoken. They can be used interchangeably for paragraphs or in line text.


46
0:6: 53,5 –>  0:7: 4,0
The document tag hide the content of the block in the slide show, but displays it in the hands-on document. Here, I am hiding a table that would be counter-productive in the slide show, but display it in the main document.

47
0:7: 4,5 –>  0:7: 20,0
The slide only tag hide the content in the hand-on document and display it in the slide show. In this example, I am displaying the image of the hand-on document on the right. I don’t wish to include this image in the main document to avoid an infinite loop of self screenshots.


48
0:7: 4,5 –>  0:7: 26,0
Finally, I am currently voicing the content of the spoken tag, that does not appear in either support.

49
0:7: 26,5 –>  0:7: 39,0
Once we have clearly delimited the different sets in the main document, the generation of the html will cleanly detangle them. CSS files, used to explicitate the format of our documents, is where the hiding and displaying takes place.

50
0:7: 39,5 –>  0:7: 55,0
We hide the different content by changing the display and visibility parameters of each class. That is were a standalone HTML file is useful, the css is passed as an argument to the pandoc tool, and does not need to be specified in the Markdown document.

51
0:7: 55,5 –>  0:7: 59,0
It allows to truly have the same original document for all supports.

52
0:7: 59,0 –>  0:8: 18,0
Using the tools are made very easy by the usage of yarn. The format of the output names is composed by the name of the original file, without extension, and the specific suffix of each output : document.HTML for the hands-on material, slides.HTML for the slide show, and slides.mp4 for the video.

53
0:8: 18,5 –>  0:8: 36,0
All the script and options are in the Jakefile running the different workflows. The parameters are hard coded for now, including the AWS login that needs to be entered in the R script using the ari package.
In the future, we will gather all the parameters in a single parameter file for an easier use.

54
0:8: 36,5 –>  0:8: 48,0
To all of you who have been preparing talks for this conference, I know you understand the struggle of adding correction to a talk video. The text-to-speech technology solve this problem, as it only necessitate editing text.

55
0:8: 48,5 –>  0:9: 04,0
Another advantage of this project is the centralization of all content in a unique document, making maintenance of the material much easier. In this project future, we want to adapt this tool to the jekyll software used by the Galaxy Training Network to convert markdown to HTML.

56
0:9: 04,5 –>  0:9: 14,0
This would permit an easier maintenance of tutorials, and the opportunity to propose video lecture. Ideally, this would become a workflow in Galaxy for an easy use.


57
0:9: 14,5 –>  0:9: 34,0
Thank you for your attention. And thank you to my co-authors and the Galaxy Project , I regret to not be able to be here for the question session of the Eastern hemisphere,
but please don’t hesitate to find me in a Bird of a feather event, or to contact me on the BCC 2020 discord if you have any question.
